{"dependencies": [{"name": "requests", "version": "2.19.1", "vulns": [{"id": "PYSEC-2018-28", "fix_versions": ["2.20.0"], "aliases": ["CVE-2018-18074", "GHSA-x84v-xcm2-53pg"], "description": "The Requests package before 2.20.0 for Python sends an HTTP Authorization header to an http URI upon receiving a same-hostname https-to-http redirect, which makes it easier for remote attackers to discover credentials by sniffing the network."}, {"id": "PYSEC-2023-74", "fix_versions": ["2.31.0"], "aliases": ["GHSA-j8r2-6x86-q33q", "CVE-2023-32681"], "description": "Requests is a HTTP library. Since Requests 2.3.0, Requests has been leaking Proxy-Authorization headers to destination servers when redirected to an HTTPS endpoint. This is a product of how we use `rebuild_proxies` to reattach the `Proxy-Authorization` header to requests. For HTTP connections sent through the tunnel, the proxy will identify the header in the request itself and remove it prior to forwarding to the destination server. However when sent over HTTPS, the `Proxy-Authorization` header must be sent in the CONNECT request as the proxy has no visibility into the tunneled request. This results in Requests forwarding proxy credentials to the destination server unintentionally, allowing a malicious actor to potentially exfiltrate sensitive information. This issue has been patched in version 2.31.0.  "}, {"id": "GHSA-9wx4-h78v-vm56", "fix_versions": ["2.32.0"], "aliases": ["CVE-2024-35195"], "description": "When making requests through a Requests `Session`, if the first request is made with `verify=False` to disable cert verification, all subsequent requests to the same origin will continue to ignore cert verification regardless of changes to the value of `verify`. This behavior will continue for the lifecycle of the connection in the connection pool.  ### Remediation Any of these options can be used to remediate the current issue, we highly recommend upgrading as the preferred mitigation.  * Upgrade to `requests>=2.32.0`. * For `requests<2.32.0`, avoid setting `verify=False` for the first request to a host while using a Requests Session. * For `requests<2.32.0`, call `close()` on `Session` objects to clear existing connections if `verify=False` is used.  ### Related Links * https://github.com/psf/requests/pull/6655"}, {"id": "GHSA-9hjg-9r4m-mvj7", "fix_versions": ["2.32.4"], "aliases": ["CVE-2024-47081"], "description": "### Impact  Due to a URL parsing issue, Requests releases prior to 2.32.4 may leak .netrc credentials to third parties for specific maliciously-crafted URLs.  ### Workarounds For older versions of Requests, use of the .netrc file can be disabled with `trust_env=False` on your Requests Session ([docs](https://requests.readthedocs.io/en/latest/api/#requests.Session.trust_env)).  ### References https://github.com/psf/requests/pull/6965 https://seclists.org/fulldisclosure/2025/Jun/2"}]}, {"name": "urllib3", "version": "1.23", "vulns": [{"id": "PYSEC-2021-108", "fix_versions": ["1.26.5"], "aliases": ["GHSA-q2q7-5pp4-w6pg", "CVE-2021-33503"], "description": "An issue was discovered in urllib3 before 1.26.5. When provided with a URL containing many @ characters in the authority component, the authority regular expression exhibits catastrophic backtracking, causing a denial of service if a URL were passed as a parameter or redirected to via an HTTP redirect."}, {"id": "PYSEC-2019-133", "fix_versions": ["1.24.2"], "aliases": ["CVE-2019-11324", "GHSA-mh33-7rrq-662w"], "description": "The urllib3 library before 1.24.2 for Python mishandles certain cases where the desired set of CA certificates is different from the OS store of CA certificates, which results in SSL connections succeeding in situations where a verification failure is the correct outcome. This is related to use of the ssl_context, ca_certs, or ca_certs_dir argument."}, {"id": "PYSEC-2019-132", "fix_versions": ["1.24.3"], "aliases": ["CVE-2019-11236", "GHSA-r64q-w8jr-g9qp"], "description": "In the urllib3 library through 1.24.1 for Python, CRLF injection is possible if the attacker controls the request parameter."}, {"id": "PYSEC-2020-148", "fix_versions": ["1.25.9"], "aliases": ["CVE-2020-26137", "GHSA-wqvq-5m8c-6g24"], "description": "urllib3 before 1.25.9 allows CRLF injection if the attacker controls the HTTP request method, as demonstrated by inserting CR and LF control characters in the first argument of putrequest(). NOTE: this is similar to CVE-2020-26116."}, {"id": "PYSEC-2023-192", "fix_versions": ["1.26.17", "2.0.6"], "aliases": ["GHSA-v845-jxx5-vc9f", "CVE-2023-43804"], "description": "urllib3 is a user-friendly HTTP client library for Python. urllib3 doesn't treat the `Cookie` HTTP header special or provide any helpers for managing cookies over HTTP, that is the responsibility of the user. However, it is possible for a user to specify a `Cookie` header and unknowingly leak information via HTTP redirects to a different origin if that user doesn't disable redirects explicitly. This issue has been patched in urllib3 version 1.26.17 or 2.0.5."}, {"id": "PYSEC-2023-207", "fix_versions": ["1.24.2"], "aliases": ["CVE-2018-25091"], "description": "urllib3 before 1.24.2 does not remove the authorization HTTP header when following a cross-origin redirect (i.e., a redirect that differs in host, port, or scheme). This can allow for credentials in the authorization header to be exposed to unintended hosts or transmitted in cleartext. NOTE: this issue exists because of an incomplete fix for CVE-2018-20060 (which was case-sensitive)."}, {"id": "PYSEC-2023-212", "fix_versions": ["1.26.18", "2.0.7"], "aliases": ["GHSA-g4mx-q9vg-27p4", "CVE-2023-45803"], "description": "urllib3 is a user-friendly HTTP client library for Python. urllib3 previously wouldn't remove the HTTP request body when an HTTP redirect response using status 301, 302, or 303 after the request had its method changed from one that could accept a request body (like `POST`) to `GET` as is required by HTTP RFCs. Although this behavior is not specified in the section for redirects, it can be inferred by piecing together information from different sections and we have observed the behavior in other major HTTP client implementations like curl and web browsers. Because the vulnerability requires a previously trusted service to become compromised in order to have an impact on confidentiality we believe the exploitability of this vulnerability is low. Additionally, many users aren't putting sensitive data in HTTP request bodies, if this is the case then this vulnerability isn't exploitable. Both of the following conditions must be true to be affected by this vulnerability: 1. Using urllib3 and submitting sensitive information in the HTTP request body (such as form data or JSON) and 2. The origin service is compromised and starts redirecting using 301, 302, or 303 to a malicious peer or the redirected-to service becomes compromised. This issue has been addressed in versions 1.26.18 and 2.0.7 and users are advised to update to resolve this issue. Users unable to update should disable redirects for services that aren't expecting to respond with redirects with `redirects=False` and disable automatic redirects with `redirects=False` and handle 301, 302, and 303 redirects manually by stripping the HTTP request body. "}, {"id": "GHSA-34jh-p97f-mpxf", "fix_versions": ["1.26.19", "2.2.2"], "aliases": ["CVE-2024-37891"], "description": "When using urllib3's proxy support with `ProxyManager`, the `Proxy-Authorization` header is only sent to the configured proxy, as expected.  However, when sending HTTP requests *without* using urllib3's proxy support, it's possible to accidentally configure the `Proxy-Authorization` header even though it won't have any effect as the request is not using a forwarding proxy or a tunneling proxy. In those cases, urllib3 doesn't treat the `Proxy-Authorization` HTTP header as one carrying authentication material and thus doesn't strip the header on cross-origin redirects.  Because this is a highly unlikely scenario, we believe the severity of this vulnerability is low for almost all users. Out of an abundance of caution urllib3 will automatically strip the `Proxy-Authorization` header during cross-origin redirects to avoid the small chance that users are doing this on accident.  Users should use urllib3's proxy support or disable automatic redirects to achieve safe processing of the `Proxy-Authorization` header, but we still decided to strip the header by default in order to further protect users who aren't using the correct approach.  ## Affected usages  We believe the number of usages affected by this advisory is low. It requires all of the following to be true to be exploited:  * Setting the `Proxy-Authorization` header without using urllib3's built-in proxy support. * Not disabling HTTP redirects. * Either not using an HTTPS origin server or for the proxy or target origin to redirect to a malicious origin.  ## Remediation  * Using the `Proxy-Authorization` header with urllib3's `ProxyManager`. * Disabling HTTP redirects using `redirects=False` when sending requests. * Not using the `Proxy-Authorization` header."}, {"id": "GHSA-pq67-6m6q-mj2v", "fix_versions": ["2.5.0"], "aliases": ["CVE-2025-50181"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}]}, {"name": "chardet", "version": "3.0.4", "vulns": []}, {"name": "idna", "version": "2.7", "vulns": [{"id": "PYSEC-2024-60", "fix_versions": ["3.7"], "aliases": ["CVE-2024-3651"], "description": "A vulnerability was identified in the kjd/idna library, specifically within the `idna.encode()` function, affecting version 3.6. The issue arises from the function's handling of crafted input strings, which can lead to quadratic complexity and consequently, a denial of service condition. This vulnerability is triggered by a crafted input that causes the `idna.encode()` function to process the input with considerable computational load, significantly increasing the processing time in a quadratic manner relative to the input size."}]}, {"name": "certifi", "version": "2018.4.16", "vulns": [{"id": "PYSEC-2022-42986", "fix_versions": ["2022.12.7"], "aliases": ["GHSA-43fp-rhv2-5gv8", "CVE-2022-23491"], "description": "Certifi is a curated collection of Root Certificates for validating the trustworthiness of SSL certificates while verifying the identity of TLS hosts. Certifi 2022.12.07 removes root certificates from \"TrustCor\" from the root store. These are in the process of being removed from Mozilla's trust store. TrustCor's root certificates are being removed pursuant to an investigation prompted by media reporting that TrustCor's ownership also operated a business that produced spyware. Conclusions of Mozilla's investigation can be found in the linked google group discussion."}, {"id": "PYSEC-2023-135", "fix_versions": ["2023.7.22"], "aliases": ["GHSA-xqr8-7jwr-rhp7", "CVE-2023-37920"], "description": "Certifi 2023.07.22 removes root certificates from \"e-Tugra\" from the root store. These are in the process of being removed from Mozilla's trust store. e-Tugra's root certificates are being removed pursuant to an investigation prompted by reporting of security issues in their systems."}]}, {"name": "flask", "version": "0.12.2", "vulns": [{"id": "PYSEC-2019-179", "fix_versions": ["1.0"], "aliases": ["GHSA-5wv5-4vpf-pj6m", "CVE-2019-1010083"], "description": "The Pallets Project Flask before 1.0 is affected by: unexpected memory usage. The impact is: denial of service. The attack vector is: crafted encoded JSON data. The fixed version is: 1. NOTE: this may overlap CVE-2018-1000656."}, {"id": "PYSEC-2018-66", "fix_versions": ["0.12.3"], "aliases": ["CVE-2018-1000656", "GHSA-562c-5r94-xh97"], "description": "The Pallets Project flask version Before 0.12.3 contains a CWE-20: Improper Input Validation vulnerability in flask that can result in Large amount of memory usage possibly leading to denial of service. This attack appear to be exploitable via Attacker provides JSON data in incorrect encoding. This vulnerability appears to have been fixed in 0.12.3. NOTE: this may overlap CVE-2019-1010083."}, {"id": "PYSEC-2023-62", "fix_versions": ["2.2.5", "2.3.2"], "aliases": ["GHSA-m2qf-hxjv-5gpq", "CVE-2023-30861"], "description": "Flask is a lightweight WSGI web application framework. When all of the following conditions are met, a response containing data intended for one client may be cached and subsequently sent by the proxy to other clients. If the proxy also caches `Set-Cookie` headers, it may send one client's `session` cookie to other clients. The severity depends on the application's use of the session and the proxy's behavior regarding cookies. The risk depends on all these conditions being met.  1. The application must be hosted behind a caching proxy that does not strip cookies or ignore responses with cookies. 2. The application sets `session.permanent = True` 3. The application does not access or modify the session at any point during a request. 4. `SESSION_REFRESH_EACH_REQUEST` enabled (the default). 5. The application does not set a `Cache-Control` header to indicate that a page is private or should not be cached.  This happens because vulnerable versions of Flask only set the `Vary: Cookie` header when the session is accessed or modified, not when it is refreshed (re-sent to update the expiration) without being accessed or modified. This issue has been fixed in versions 2.3.2 and 2.2.5."}]}, {"name": "werkzeug", "version": "0.12.2", "vulns": [{"id": "PYSEC-2019-140", "fix_versions": ["0.15.3"], "aliases": ["GHSA-gq9m-qvpx-68hc", "CVE-2019-14806"], "description": "Pallets Werkzeug before 0.15.3, when used with Docker, has insufficient debugger PIN randomness because Docker containers share the same machine id."}, {"id": "PYSEC-2022-203", "fix_versions": ["2.1.1"], "aliases": ["CVE-2022-29361"], "description": "** DISPUTED ** Improper parsing of HTTP requests in Pallets Werkzeug v2.1.0 and below allows attackers to perform HTTP Request Smuggling using a crafted HTTP request with multiple requests included inside the body. NOTE: the vendor's position is that this behavior can only occur in unsupported configurations involving development mode and an HTTP server from outside the Werkzeug project."}, {"id": "PYSEC-2023-58", "fix_versions": ["2.2.3"], "aliases": ["CVE-2023-25577", "GHSA-xg9f-g7g7-2323"], "description": "Werkzeug is a comprehensive WSGI web application library. Prior to version 2.2.3, Werkzeug's multipart form data parser will parse an unlimited number of parts, including file parts. Parts can be a small amount of bytes, but each requires CPU time to parse and may use more memory as Python data. If a request can be made to an endpoint that accesses `request.data`, `request.form`, `request.files`, or `request.get_data(parse_form_data=False)`, it can cause unexpectedly high resource usage. This allows an attacker to cause a denial of service by sending crafted multipart data to an endpoint that will parse it. The amount of CPU time required can block worker processes from handling legitimate requests. The amount of RAM required can trigger an out of memory kill of the process. Unlimited file parts can use up memory and file handles. If many concurrent requests are sent continuously, this can exhaust or kill all available workers. Version 2.2.3 contains a patch for this issue."}, {"id": "PYSEC-2023-57", "fix_versions": ["2.2.3"], "aliases": ["CVE-2023-23934", "GHSA-px8h-6qxv-m22q"], "description": "Werkzeug is a comprehensive WSGI web application library. Browsers may allow \"nameless\" cookies that look like `=value` instead of `key=value`. A vulnerable browser may allow a compromised application on an adjacent subdomain to exploit this to set a cookie like `=__Host-test=bad` for another subdomain. Werkzeug prior to 2.2.3 will parse the cookie `=__Host-test=bad` as __Host-test=bad`. If a Werkzeug application is running next to a vulnerable or malicious subdomain which sets such a cookie using a vulnerable browser, the Werkzeug application will see the bad cookie value but the valid cookie key. The issue is fixed in Werkzeug 2.2.3."}, {"id": "PYSEC-2023-221", "fix_versions": ["2.3.8", "3.0.1"], "aliases": ["GHSA-hrfv-mqp8-q5rw", "CVE-2023-46136"], "description": "Werkzeug is a comprehensive WSGI web application library. If an upload of a file that starts with CR or LF and then is followed by megabytes of data without these characters: all of these bytes are appended chunk by chunk into internal bytearray and lookup for boundary is performed on growing buffer. This allows an attacker to cause a denial of service by sending crafted multipart data to an endpoint that will parse it. The amount of CPU time required can block worker processes from handling legitimate requests. This vulnerability has been patched in version 3.0.1."}, {"id": "GHSA-j544-7q9p-6xp8", "fix_versions": ["0.15.5"], "aliases": ["CVE-2019-14322"], "description": "In Pallets Werkzeug before 0.15.5, SharedDataMiddleware mishandles drive names (such as C:) in Windows pathnames."}, {"id": "GHSA-2g68-c3qc-8985", "fix_versions": ["3.0.3"], "aliases": ["CVE-2024-34069"], "description": "The debugger in affected versions of Werkzeug can allow an attacker to execute code on a developer's machine under some circumstances. This requires the attacker to get the developer to interact with a domain and subdomain they control, and enter the debugger PIN, but if they are successful it allows access to the debugger even if it is only running on localhost. This also requires the attacker to guess a URL in the developer's application that will trigger the debugger."}, {"id": "GHSA-f9vj-2wh5-fj8j", "fix_versions": ["3.0.6"], "aliases": ["CVE-2024-49766"], "description": "On Python < 3.11 on Windows, `os.path.isabs()` does not catch UNC paths like `//server/share`. Werkzeug's `safe_join()` relies on this check, and so can produce a path that is not safe, potentially allowing unintended access to data. Applications using Python >= 3.11, or not using Windows, are not vulnerable."}, {"id": "GHSA-q34m-jh98-gwm2", "fix_versions": ["3.0.6"], "aliases": ["CVE-2024-49767"], "description": "Applications using Werkzeug to parse `multipart/form-data` requests are vulnerable to resource exhaustion. A specially crafted form body can bypass the `Request.max_form_memory_size` setting.   The `Request.max_content_length` setting, as well as resource limits provided by deployment software and platforms, are also available to limit the resources used during a request. This vulnerability does not affect those settings. All three types of limits should be considered and set appropriately when deploying an application."}]}, {"name": "jinja2", "version": "2.10", "vulns": [{"id": "PYSEC-2021-66", "fix_versions": ["2.11.3"], "aliases": ["SNYK-PYTHON-JINJA2-1012994", "GHSA-g3rq-g295-4j3m", "CVE-2020-28493"], "description": "This affects the package jinja2 from 0.0.0 and before 2.11.3. The ReDoS vulnerability is mainly due to the `_punctuation_re regex` operator and its use of multiple wildcards. The last wildcard is the most exploitable as it searches for trailing punctuation. This issue can be mitigated by Markdown to format user content instead of the urlize filter, or by implementing request timeouts and limiting process memory."}, {"id": "PYSEC-2019-217", "fix_versions": ["2.10.1"], "aliases": ["GHSA-462w-v97r-4m45", "CVE-2019-10906"], "description": "In Pallets Jinja before 2.10.1, str.format_map allows a sandbox escape."}, {"id": "GHSA-h5c8-rqwp-cp95", "fix_versions": ["3.1.3"], "aliases": ["CVE-2024-22195"], "description": "The `xmlattr` filter in affected versions of Jinja accepts keys containing spaces. XML/HTML attributes cannot contain spaces, as each would then be interpreted as a separate attribute. If an application accepts keys (as opposed to only values) as user input, and renders these in pages that other users see as well, an attacker could use this to inject other attributes and perform XSS. Note that accepting keys as user input is not common or a particularly intended use case of the `xmlattr` filter, and an application doing so should already be verifying what keys are provided regardless of this fix."}, {"id": "GHSA-h75v-3vvj-5mfj", "fix_versions": ["3.1.4"], "aliases": ["CVE-2024-34064"], "description": "The `xmlattr` filter in affected versions of Jinja accepts keys containing non-attribute characters. XML/HTML attributes cannot contain spaces, `/`, `>`, or `=`, as each would then be interpreted as starting a separate attribute. If an application accepts keys (as opposed to only values) as user input, and renders these in pages that other users see as well, an attacker could use this to inject other attributes and perform XSS. The fix for the previous GHSA-h5c8-rqwp-cp95 CVE-2024-22195 only addressed spaces but not other characters.  Accepting keys as user input is now explicitly considered an unintended use case of the `xmlattr` filter, and code that does so without otherwise validating the input should be flagged as insecure, regardless of Jinja version. Accepting _values_ as user input continues to be safe."}, {"id": "GHSA-q2x7-8rv6-6q7h", "fix_versions": ["3.1.5"], "aliases": ["CVE-2024-56326"], "description": "An oversight in how the Jinja sandboxed environment detects calls to `str.format` allows an attacker that controls the content of a template to execute arbitrary Python code.  To exploit the vulnerability, an attacker needs to control the content of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates.  Jinja's sandbox does catch calls to `str.format` and ensures they don't escape the sandbox. However, it's possible to store a reference to a malicious string's `format` method, then pass that to a filter that calls it. No such filters are built-in to Jinja, but could be present through custom filters in an application. After the fix, such indirect calls are also handled by the sandbox."}, {"id": "GHSA-cpwx-vrp4-4pq7", "fix_versions": ["3.1.6"], "aliases": ["CVE-2025-27516"], "description": "An oversight in how the Jinja sandboxed environment interacts with the `|attr` filter allows an attacker that controls the content of a template to execute arbitrary Python code.  To exploit the vulnerability, an attacker needs to control the content of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates.  Jinja's sandbox does catch calls to `str.format` and ensures they don't escape the sandbox. However, it's possible to use the `|attr` filter to get a reference to a string's plain format method, bypassing the sandbox. After the fix, the `|attr` filter no longer bypasses the environment's attribute lookup."}]}, {"name": "itsdangerous", "version": "0.24", "vulns": []}, {"name": "click", "version": "6.7", "vulns": []}, {"name": "markupsafe", "version": "1.1.0", "vulns": []}, {"name": "pyyaml", "version": "5.1", "vulns": [{"id": "PYSEC-2020-176", "fix_versions": ["5.2b1"], "aliases": ["GHSA-3pqx-4fqf-j49f", "CVE-2019-20477"], "description": "PyYAML 5.1 through 5.1.2 has insufficient restrictions on the load and load_all functions because of a class deserialization issue, e.g., Popen is a class in the subprocess module. NOTE: this issue exists because of an incomplete fix for CVE-2017-18342."}, {"id": "PYSEC-2020-96", "fix_versions": ["5.3.1"], "aliases": ["CVE-2020-1747", "GHSA-6757-jp84-gxfx"], "description": "A vulnerability was discovered in the PyYAML library in versions before 5.3.1, where it is susceptible to arbitrary code execution when it processes untrusted YAML files through the full_load method or with the FullLoader loader. Applications that use the library to process untrusted input may be vulnerable to this flaw. An attacker could use this flaw to execute arbitrary code on the system by abusing the python/object/new constructor."}, {"id": "PYSEC-2021-142", "fix_versions": ["5.4"], "aliases": ["GHSA-8q59-q68h-6hv4", "CVE-2020-14343"], "description": "A vulnerability was discovered in the PyYAML library in versions before 5.4, where it is susceptible to arbitrary code execution when it processes untrusted YAML files through the full_load method or with the FullLoader loader. Applications that use the library to process untrusted input may be vulnerable to this flaw. This flaw allows an attacker to execute arbitrary code on the system by abusing the python/object/new constructor. This flaw is due to an incomplete fix for CVE-2020-1747."}]}, {"name": "pillow", "version": "9.0.0", "vulns": [{"id": "PYSEC-2022-168", "fix_versions": ["9.0.1"], "aliases": ["GHSA-9j59-75qj-795w", "CVE-2022-24303"], "description": "Pillow before 9.0.1 allows attackers to delete files because spaces in temporary pathnames are mishandled."}, {"id": "PYSEC-2022-42979", "fix_versions": ["9.2.0"], "aliases": ["CVE-2022-45198"], "description": "Pillow before 9.2.0 performs Improper Handling of Highly Compressed GIF Data (Data Amplification)."}, {"id": "PYSEC-2023-175", "fix_versions": ["10.0.1"], "aliases": [], "description": "Pillow versions before v10.0.1 bundled libwebp binaries in wheels that are vulnerable to CVE-2023-5129 (previously CVE-2023-4863). Pillow v10.0.1 upgrades the bundled libwebp binary to v1.3.2."}, {"id": "PYSEC-2023-227", "fix_versions": ["10.0.0"], "aliases": ["CVE-2023-44271"], "description": "An issue was discovered in Pillow before 10.0.0. It is a Denial of Service that uncontrollably allocates memory to process a given task, potentially causing a service to crash by having it run out of memory. This occurs for truetype in ImageFont when textlength in an ImageDraw instance operates on a long text argument."}, {"id": "GHSA-8vj2-vxx3-667w", "fix_versions": ["9.0.1"], "aliases": ["CVE-2022-22817"], "description": "`PIL.ImageMath.eval` in Pillow before 9.0.0 allows evaluation of arbitrary expressions, such as ones that use the Python exec method `ImageMath.eval(\"exec(exit())\")`.  While Pillow 9.0.0 restricted top-level builtins available to PIL.ImageMath.eval(), it did not prevent builtins available to lambda expressions. These are now also restricted in 9.0.1."}, {"id": "GHSA-3f63-hfp8-52jq", "fix_versions": ["10.2.0"], "aliases": ["CVE-2023-50447"], "description": "Pillow through 10.1.0 allows PIL.ImageMath.eval Arbitrary Code Execution via the environment parameter, a different vulnerability than CVE-2022-22817 (which was about the expression parameter)."}, {"id": "GHSA-j7hp-h8jx-5ppr", "fix_versions": ["10.0.1"], "aliases": ["CVE-2023-4863"], "description": "Heap buffer overflow in libwebp allow a remote attacker to perform an out of bounds memory write via a crafted HTML page."}, {"id": "GHSA-44wm-f244-xhp3", "fix_versions": ["10.3.0"], "aliases": ["CVE-2024-28219"], "description": "In _imagingcms.c in Pillow before 10.3.0, a buffer overflow exists because strcpy is used instead of strncpy."}]}, {"name": "pygments", "version": "2.7.2", "vulns": [{"id": "PYSEC-2021-140", "fix_versions": ["2.7.4"], "aliases": ["GHSA-9w8r-397f-prfh", "CVE-2021-20270"], "description": "An infinite loop in SMLLexer in Pygments versions 1.5 to 2.7.3 may lead to denial of service when performing syntax highlighting of a Standard ML (SML) source file, as demonstrated by input that only contains the \"exception\" keyword."}, {"id": "PYSEC-2021-141", "fix_versions": ["2.7.4"], "aliases": ["GHSA-pq64-v7f5-gqh8", "CVE-2021-27291"], "description": "In pygments 1.1+, fixed in 2.7.4, the lexers used to parse programming languages rely heavily on regular expressions. Some of the regular expressions have exponential or cubic worst-case complexity and are vulnerable to ReDoS. By crafting malicious input, an attacker can cause a denial of service."}, {"id": "PYSEC-2023-117", "fix_versions": ["2.15.1"], "aliases": ["CVE-2022-40896"], "description": "A ReDoS issue was discovered in pygments/lexers/smithy.py in pygments through 2.15.0 via SmithyLexer."}]}, {"name": "tornado", "version": "6.0.3", "vulns": [{"id": "PYSEC-2023-75", "fix_versions": ["6.3.2"], "aliases": ["CVE-2023-28370"], "description": "Open redirect vulnerability in Tornado versions 6.3.1 and earlier allows a remote unauthenticated attacker to redirect a user to an arbitrary web site and conduct a phishing attack by having user access a specially crafted URL."}, {"id": "GHSA-qppv-j76h-2rpx", "fix_versions": ["6.3.3"], "aliases": [], "description": "## Summary Tornado interprets `-`, `+`, and `_` in chunk length and `Content-Length` values, which are not allowed by the HTTP RFCs. This can result in request smuggling when Tornado is deployed behind certain proxies that interpret those non-standard characters differently. This is known to apply to older versions of haproxy, although the current release is not affected.  ## Details Tornado uses the `int` constructor to parse the values of `Content-Length` headers and chunk lengths in the following locations: ### `tornado/http1connection.py:445` ```python3             self._expected_content_remaining = int(headers[\"Content-Length\"]) ``` ### `tornado/http1connection.py:621` ```python3                 content_length = int(headers[\"Content-Length\"])  # type: Optional[int] ``` ### `tornado/http1connection.py:671` ```python3             chunk_len = int(chunk_len_str.strip(), 16) ``` Because `int(\"0_0\") == int(\"+0\") == int(\"-0\") == int(\"0\")`, using the `int` constructor to parse and validate strings that should contain only ASCII digits is not a good strategy.   "}, {"id": "GHSA-753j-mpmx-qq6g", "fix_versions": ["6.4.1"], "aliases": [], "description": "### Summary When Tornado receives a request with two `Transfer-Encoding: chunked` headers, it ignores them both. This enables request smuggling when Tornado is deployed behind a proxy server that emits such requests. [Pound](https://en.wikipedia.org/wiki/Pound_(networking)) does this.  ### PoC 0. Install Tornado. 1. Start a simple Tornado server that echoes each received request's body: ```bash cat << EOF > server.py import asyncio import tornado  class MainHandler(tornado.web.RequestHandler):     def post(self):         self.write(self.request.body)  async def main():     tornado.web.Application([(r\"/\", MainHandler)]).listen(8000)     await asyncio.Event().wait()  asyncio.run(main()) EOF python3 server.py & ``` 2. Send a valid chunked request: ```bash printf 'POST / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n1\\r\\nZ\\r\\n0\\r\\n\\r\\n' | nc localhost 8000 ``` 3. Observe that the response is as expected: ``` HTTP/1.1 200 OK Server: TornadoServer/6.3.3 Content-Type: text/html; charset=UTF-8 Date: Sat, 07 Oct 2023 17:32:05 GMT Content-Length: 1  Z ``` 4. Send a request with two `Transfer-Encoding: chunked` headers: ``` printf 'POST / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n1\\r\\nZ\\r\\n0\\r\\n\\r\\n' | nc localhost 8000 ``` 5. Observe the strange response: ``` HTTP/1.1 200 OK Server: TornadoServer/6.3.3 Content-Type: text/html; charset=UTF-8 Date: Sat, 07 Oct 2023 17:35:40 GMT Content-Length: 0  HTTP/1.1 400 Bad Request  ``` This is because Tornado believes that the request has no message body, so it tries to interpret `1\\r\\nZ\\r\\n0\\r\\n\\r\\n` as its own request, which causes a 400 response. With a little cleverness involving `chunk-ext`s, you can get Tornado to instead respond 405, which has the potential to desynchronize the connection, as opposed to 400 which should always result in a connection closure.  ### Impact Anyone using Tornado behind a proxy that forwards requests containing multiple `Transfer-Encoding: chunked` headers is vulnerable to request smuggling, which may entail ACL bypass, cache poisoning, or connection desynchronization. "}, {"id": "GHSA-w235-7p84-xx57", "fix_versions": ["6.4.1"], "aliases": [], "description": "### Summary Tornado\u2019s `curl_httpclient.CurlAsyncHTTPClient` class is vulnerable to CRLF (carriage return/line feed) injection in the request headers.  ### Details When an HTTP request is sent using `CurlAsyncHTTPClient`, Tornado does not reject carriage return (\\r) or line feed (\\n) characters in the request headers. As a result, if an application includes an attacker-controlled header value in a request sent using `CurlAsyncHTTPClient`, the attacker can inject arbitrary headers into the request or cause the application to send arbitrary requests to the specified server.  This behavior differs from that of the standard `AsyncHTTPClient` class, which does reject CRLF characters.  This issue appears to stem from libcurl's (as well as pycurl's) lack of validation for the [`HTTPHEADER`](https://curl.se/libcurl/c/CURLOPT_HTTPHEADER.html) option. libcurl\u2019s documentation states:  > The headers included in the linked list must not be CRLF-terminated, because libcurl adds CRLF after each header item itself. Failure to comply with this might result in strange behavior. libcurl passes on the verbatim strings you give it, without any filter or other safe guards. That includes white space and control characters.  pycurl similarly appears to assume that the headers adhere to the correct format. Therefore, without any validation on Tornado\u2019s part, header names and values are included verbatim in the request sent by `CurlAsyncHTTPClient`, including any control characters that have special meaning in HTTP semantics.  ### PoC The issue can be reproduced using the following script:  ```python import asyncio  from tornado import httpclient from tornado import curl_httpclient  async def main():     http_client = curl_httpclient.CurlAsyncHTTPClient()      request = httpclient.HTTPRequest(         # Burp Collaborator payload         \"http://727ymeu841qydmnwlol261ktkkqbe24qt.oastify.com/\",         method=\"POST\",         body=\"body\",         # Injected header using CRLF characters         headers={\"Foo\": \"Bar\\r\\nHeader: Injected\"}     )      response = await http_client.fetch(request)     print(response.body)      http_client.close()  if __name__ == \"__main__\":     asyncio.run(main()) ```  When the specified server receives the request, it contains the injected header (`Header: Injected`) on its own line:  ```http POST / HTTP/1.1 Host: 727ymeu841qydmnwlol261ktkkqbe24qt.oastify.com User-Agent: Mozilla/5.0 (compatible; pycurl) Accept: */* Accept-Encoding: gzip,deflate Foo: Bar Header: Injected Content-Length: 4 Content-Type: application/x-www-form-urlencoded  body ```  The attacker can also construct entirely new requests using a payload with multiple CRLF sequences. For example, specifying a header value of `\\r\\n\\r\\nPOST /attacker-controlled-url HTTP/1.1\\r\\nHost: 727ymeu841qydmnwlol261ktkkqbe24qt.oastify.com` results in the server receiving an additional, attacker-controlled request:  ```http POST /attacker-controlled-url HTTP/1.1 Host: 727ymeu841qydmnwlol261ktkkqbe24qt.oastify.com Content-Length: 4 Content-Type: application/x-www-form-urlencoded  body ```  ### Impact Applications using the Tornado library to send HTTP requests with untrusted header data are affected. This issue may facilitate the exploitation of server-side request forgery (SSRF) vulnerabilities."}, {"id": "GHSA-7cx3-6m66-7c5m", "fix_versions": ["6.5"], "aliases": ["CVE-2025-47287"], "description": "### Summary  When Tornado's ``multipart/form-data`` parser encounters certain errors, it logs a warning but continues trying to parse the remainder of the data. This allows remote attackers to generate an extremely high volume of logs, constituting a DoS attack. This DoS is compounded by the fact that the logging subsystem is synchronous.  ### Affected versions  All versions of Tornado prior to 6.5 are affected. The vulnerable parser is enabled by default.  ### Solution  Upgrade to Tornado version 6.5. In the meantime, risk can be mitigated by blocking `Content-Type: multipart/form-data` in a proxy."}, {"id": "GHSA-8w49-h785-mj3c", "fix_versions": ["6.4.2"], "aliases": ["CVE-2024-52804"], "description": "The algorithm used for parsing HTTP cookies in Tornado versions prior to 6.4.2 sometimes has quadratic complexity, leading to excessive CPU consumption when parsing maliciously-crafted cookie headers. This parsing occurs in the event loop thread and may block the processing of other requests.  See also CVE-2024-7592 for a similar vulnerability in cpython."}]}], "fixes": []}
